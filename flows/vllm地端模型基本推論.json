{
  "description": "Perform basic prompting with an OpenAI model.",
  "user_id": "9d405971-4a8c-4427-bcbb-686af9087d2e",
  "endpoint_name": null,
  "id": "38a705e7-1a62-41b4-8921-8b090c59ef8e",
  "tags": null,
  "locked": false,
  "gradient": "2",
  "folder_id": "cf089980-3cbc-48d8-b29f-2583b5c19a69",
  "is_component": false,
  "data": {
    "nodes": [
      {
        "data": {
          "description": "Get chat inputs from the Playground.",
          "display_name": "Chat Input",
          "id": "ChatInput-FKyB0",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.2.0",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "å®¢æœï¼šä¸­è¯é›»ä¿¡ä½ å¥½ï¼Œæ•å§“ç°¡ï¼Œå¾ˆæ¦®å¹¸ç‚ºä½ æœå‹™ã€‚è«‹å•æœ‰ä»€éº¼éœ€è¦å¹«å¿™çš„ï¼Ÿ\næ°‘çœ¾ï¼šå°å§ä½ å¥½ï¼Œæˆ‘é€™é‚Šçš„å¯¬é »ç¶²è·¯å·²ç¶“é€šäº†ã€‚\nå®¢æœï¼šæ˜¯çš„ã€‚é‚£æˆ‘å¹«ä½ è½‰æ¥åˆ°å¯¬é »å®¢æœéƒ¨é–€ï¼Œè«‹å°ˆäººå”åŠ©ä½ ã€‚é›»è©±å…ˆä¸è¦æ›ï¼Œæˆ‘å¹«ä½ è½‰éå»ã€‚\næ°‘çœ¾ï¼šå¥½ã€‚\n\nï¼ˆè½‰æ¥å¾Œï¼‰\n\nå®¢æœï¼šä¸­è¯é›»ä¿¡ä½ å¥½ï¼Œæ•å§“*ï¼Œå¾ˆé«˜èˆˆç‚ºä½ æœå‹™ã€‚\næ°‘çœ¾ï¼šæ¬¸ï¼Œå°å§ä½ å¥½ã€‚æˆ‘å€‘å®¶çš„ç¶²è·¯ä¸é€šäº†ã€‚\nå®¢æœï¼šç¶²è·¯å—ï¼Ÿå¥½çš„ï¼Œæˆ‘å…ˆå¹«ä½ æŸ¥è©¢ï¼Œè«‹å•æ€éº¼ç¨±å‘¼æ‚¨ï¼Ÿ\næ°‘çœ¾ï¼šæˆ‘å§“*ã€‚\nå®¢æœï¼šå¥½çš„ï¼Œå°å§ï¼Œè«‹å•ç¶²è·¯è¨­å‚™çš„å¸‚å…§é›»è©±è™Ÿç¢¼æ˜¯å¤šå°‘ï¼Ÿ\næ°‘çœ¾ï¼šæ˜¯é€™ä¸€æ”¯ã€‚\nå®¢æœï¼šä¸å¥½æ„æ€ï¼Œè«‹å•æœ‰å¸‚å…§é›»è©±å—ï¼Ÿ\næ°‘çœ¾ï¼šæ˜¯388-ã€‚\nå®¢æœï¼šå¥½çš„ï¼Œè«‹ç¨ç­‰ä¸€ä¸‹ã€‚å°å§ï¼Œæ„Ÿè¬ä½ çš„è€å€™ã€‚ç¢ºèªä¸€ä¸‹è¨­å‚™åœ°å€æ˜¯åœ¨ä»€éº¼è·¯å¹¾è™Ÿå‘¢ï¼Ÿ\næ°‘çœ¾ï¼šæˆ‘åœ¨å¤§æºªã€‚åŒ—å¤§æºªå€ç¾è¯é‡Œé †å’Œè·¯è™Ÿã€‚\nå®¢æœï¼šè¬è¬ä½ çš„è³‡æ–™æä¾›ã€‚ç›®å‰æŸ¥è©¢å¸‚è©±éƒ¨åˆ†ï¼Œé€™é‚Šæ˜¯æ²’æœ‰ç¶²è·¯è³‡æ–™ï¼Œé‚£æˆ‘ç”¨åœ°å€å†åšç¢ºèªï¼Œè«‹ç¨ç­‰ä¸€ä¸‹ã€‚\næ°‘çœ¾ï¼šå¥½ã€‚æˆ‘ç¾åœ¨å®Œå…¨ç„¡æ³•ä¸Šç¶²ã€‚\nå®¢æœï¼šè«‹å•æ•¸æ“šæ©Ÿä¸Šçš„ç´…ç‡ˆæœ‰äº®å—ï¼Ÿ\næ°‘çœ¾ï¼šæ²’æœ‰ã€‚æˆ‘å‰›å‰›ç™¼ç¾å®ƒç„¡æ³•é€²ä¾†ï¼Œæ‰€ä»¥æˆ‘é‡æ’äº†ä¸€æ¬¡ã€‚çµæœç¾åœ¨æ‰€æœ‰çš„ç‡ˆè™Ÿå…¨éƒ¨éƒ½æ²’æœ‰äº†ã€‚\nå®¢æœï¼šäº†è§£ï¼Œé‚£å°å§ï¼Œæˆ‘å€‘ç¾åœ¨å…ˆåšä¸€ä¸‹è¨Šè™Ÿæ¸¬è©¦ï¼Œè«‹ç¨ç­‰ä¸€ä¸‹ï¼Œè¬è¬ã€‚\næ°‘çœ¾ï¼šå¥½ï¼Œè¬è¬ã€‚å®Œå…¨æ²’æœ‰ç‡ˆè™Ÿï¼Œæ‡‰è©²æ˜¯æ¸¬è©¦ã€‚\nå®¢æœï¼šå°å§ï¼Œæ„Ÿè¬ä½ çš„è€å€™ã€‚ç›®å‰æˆ‘å€‘ç³»çµ±åµæ¸¬ç·šè·¯æ­£å¸¸ï¼Œæœ‰åµæ¸¬åˆ°å‰›å‰›æœ‰è¨Šè™Ÿé‡é€çš„è¨˜éŒ„ã€‚è«‹å•ä½ å‰›æŠŠæ’é ­æ‹”æ‰é‡æ’å›å»ä¹‹å¾Œï¼Œç¾åœ¨å®Œå…¨ä¸äº®ç‡ˆå—ï¼Ÿ\næ°‘çœ¾ï¼šå°ï¼Œå®Œå…¨ä¸äº®ã€‚\nå®¢æœï¼šäº†è§£ï¼Œä¸å¥½æ„æ€ï¼Œè«‹å†å¹«æˆ‘é‡è©¦ä¸€æ¬¡ï¼ŒæŠŠæ’é ­æ‹”æ‰é‡æ’å›å»ï¼Œçœ‹çœ‹æ˜¯å¦é‚„æ˜¯æ²’æœ‰åæ‡‰ï¼Ÿ\næ°‘çœ¾ï¼šå¥½ï¼Œè¬è¬ã€‚ç¾åœ¨è©¦ä¸€ä¸‹ã€‚é‚„æ˜¯æ²’æœ‰äº®ç‡ˆã€‚\nå®¢æœï¼šé‚„æ˜¯æ²’æœ‰äº®ç‡ˆã€‚äº†è§£ï¼Œé‚£é€™æ¨£çš„è©±ï¼Œæˆ‘å€‘éœ€è«‹å·¥ç¨‹å¸«ç¢ºèªæ˜¯å¦æ˜¯ç·šè·¯æˆ–è¨­å‚™çš„å•é¡Œã€‚\næ°‘çœ¾ï¼šé€™æ¨£å­å•Šï¼Œæˆ‘å®Œå…¨æ²’æœ‰äº®ç‡ˆï¼Œå°ã€‚å¥‡æ€ªï¼Œæˆ‘é‡æ’ä¹‹å¾Œé‚„æ˜¯æ²’æœ‰è¨Šè™Ÿï¼Œæ‰€ä»¥æˆ‘å†é‡æŸ¥ä¸€æ¬¡ã€‚\nå®¢æœï¼šäº†è§£ï¼Œä¸å¥½æ„æ€ï¼Œæˆ‘å€‘æœƒå…ˆæª¢æŸ¥å¤–ç¸£æ©Ÿæˆ¿ã€‚\næ°‘çœ¾ï¼šæœƒä¸æœƒæ˜¯å¤–é¢çš„ç·šé€²ä¸ä¾†ï¼Ÿ\nå®¢æœï¼šæœ‰å¯èƒ½ï¼Œæˆ‘å€‘æœƒå…ˆæª¢æŸ¥å¤–ç¸£æ©Ÿæˆ¿ï¼Œç¢ºèªå•é¡Œã€‚\næ°‘çœ¾ï¼šå°ï¼Œå› ç‚ºæˆ‘ä½é€™é‚Š100ç±³å…§å¸¸æœ‰æ•…éšœã€‚\nå®¢æœï¼šäº†è§£ã€‚è«‹æä¾›è¯çµ¡é›»è©±ï¼Œæ–¹ä¾¿é€šçŸ¥ã€‚\næ°‘çœ¾ï¼šæ˜¯**--ï¼Œæˆ‘å§“*ã€‚\nå®¢æœï¼šå¥½çš„ï¼Œè«‹å•æ˜¯è¯çµ¡*å°å§å—ï¼Ÿ\næ°‘çœ¾ï¼šå°ã€‚\nå®¢æœï¼šå¥½ï¼ŒçŸ¥é“äº†ã€‚å¦‚æœç¢ºå®šæ˜¯å¤–ç¸£å•é¡Œï¼Œæˆ‘å€‘æœƒç›´æ¥è™•ç†ä¿®å¾©ï¼Œä¸¦æå‰é€šçŸ¥æ‚¨ã€‚å¦‚æœå·¥ç¨‹å¸«éœ€è¦åˆ°ç¾å ´æª¢æ¸¬ï¼Œæœ€å¿«æœƒåœ¨æ˜å¤©è¯çµ¡ç¢ºèªã€‚\næ°‘çœ¾ï¼šé‚£ä»Šå¤©å°±æ²’è¾¦æ³•ä¸Šç¶²äº†ï¼Ÿ\nå®¢æœï¼šæ˜¯çš„ï¼Œæˆ‘å€‘æœƒå…ˆç›¡å¿«æª¢æŸ¥å¤–ç·šï¼Œå¦‚æœæ˜¯å¤–ç·šå•é¡Œè™•ç†å®Œæˆæœƒææ—©é€šçŸ¥æ‚¨ã€‚\næ°‘çœ¾ï¼šå¥½çš„ï¼Œé‚£å°±éº»ç…©ä½ äº†ã€‚\nå®¢æœï¼šä¸æœƒï¼Œè¬è¬æ‚¨çš„ä¾†é›»ã€‚\næ°‘çœ¾ï¼šå¥½ï¼Œè¬è¬ï¼Œå†è¦‹ã€‚\n\nï¼ˆé€šè©±çµæŸï¼‰"
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "type": "ChatInput"
        },
        "dragging": false,
        "height": 234,
        "id": "ChatInput-FKyB0",
        "measured": {
          "height": 234,
          "width": 320
        },
        "position": {
          "x": 370.6367779779016,
          "y": 708.5717478728378
        },
        "positionAbsolute": {
          "x": 689.5720422421635,
          "y": 765.155834131403
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-WPdXW",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "å°‡\"{user_query}\"é€²è¡Œå°è©±é€²è¡Œæ‘˜è¦\nç”¨ç¹é«”ä¸­æ–‡å›è¦†ï¼Œä¸è¦å‡ºç¾å¥‡æ€ªçš„æ–‡å­—ç¬¦è™Ÿ\n\nå›æ‡‰ç¯„ä¾‹\nå®¢æˆ¶å•é¡Œï¼š50å­—å…§å®¹\nå®¢æœå›æ‡‰ï¼š50å­—å…§å®¹\nè™•ç†éç¨‹ï¼š100å­—å…§å®¹\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "user_query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "user_query",
                "display_name": "user_query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": [
                "user_query"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 260,
        "id": "Prompt-WPdXW",
        "measured": {
          "height": 260,
          "width": 320
        },
        "position": {
          "x": 394.776022018222,
          "y": 1193.0360973282798
        },
        "positionAbsolute": {
          "x": 690.2015147036818,
          "y": 1018.5443911764344
        },
        "selected": true,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "note-mVHCn",
          "node": {
            "description": "### ğŸ’¡ Add your OpenAI API key here ğŸ‘‡",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "transparent"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-mVHCn",
        "measured": {
          "height": 324,
          "width": 324
        },
        "position": {
          "x": 1075.829573520873,
          "y": 657.2057655038416
        },
        "positionAbsolute": {
          "x": 1075.829573520873,
          "y": 657.2057655038416
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 324
        },
        "type": "noteNode",
        "width": 324
      },
      {
        "data": {
          "id": "ChatOutput-6Q1eR",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return (\n                    data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n                    .applymap(lambda x: (str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x))\n                    .to_markdown(index=False)\n                )\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 234,
        "id": "ChatOutput-6Q1eR",
        "measured": {
          "height": 234,
          "width": 320
        },
        "position": {
          "x": 1465.185090522481,
          "y": 889.4702700553373
        },
        "positionAbsolute": {
          "x": 1444.936881624563,
          "y": 872.7273956769025
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "id": "CustomComponent-NnG1e",
        "type": "genericNode",
        "position": {
          "x": 931.3266806127824,
          "y": 781.9992874749792
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import requests\r\nfrom langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema import Data\r\nfrom langflow.schema.message import Message  # å¼•å…¥ Message é¡\r\n\r\n\r\nclass CustomVLLMComponent(Component):\r\n    display_name = \"vLLM Inference\"\r\n    description = \"A custom component to perform inference using a local vLLM model.\"\r\n    documentation: str = \"https://docs.langflow.org/components-custom-components\"\r\n    icon = \"brain\"\r\n    name = \"CustomVLLMComponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"input_value\",\r\n            display_name=\"Input Value\",\r\n            info=\"Additional input value to include in the request.\",\r\n            value=\"Provide a short answer.\",\r\n            tool_mode=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"prompt\",\r\n            display_name=\"Prompt\",\r\n            info=\"The prompt to send to the vLLM model.\",\r\n            value=\"Hello, how can I assist you today?\",\r\n            tool_mode=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"model\",\r\n            display_name=\"Model\",\r\n            info=\"The vLLM model path or name to use for inference.\",\r\n            value=\"/models/models--meta-llama--Llama-3.1-8B-Instruct/snapshots/manual-20250305\",\r\n            tool_mode=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"max_tokens\",\r\n            display_name=\"Max Tokens\",\r\n            info=\"The maximum number of tokens to generate.\",\r\n            value=\"512\",  # é è¨­å€¼è¨­ç‚º 512\r\n            tool_mode=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"temperature\",\r\n            display_name=\"Temperature\",\r\n            info=\"Controls the randomness of the output (0.0 to 1.0).\",\r\n            value=\"0.8\",  # é è¨­å€¼è¨­ç‚º 0.8\r\n            tool_mode=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Response\", name=\"response\", method=\"build_response\"),\r\n    ]\r\n\r\n    def build_response(self) -> Message:  # è¿”å› Message è€Œä¸æ˜¯ Data\r\n        # çµ„åˆ prompt å’Œ input_value\r\n        combined_prompt = f\"{self.prompt}\\n{self.input_value}\"\r\n\r\n        # vLLM API ç«¯é»\r\n        url = \"http://vllm:8000/v1/completions\"\r\n        headers = {\"Content-Type\": \"application/json\"}\r\n        payload = {\r\n            \"model\": self.model,  # ä½¿ç”¨è¼¸å…¥çš„ model å€¼\r\n            \"prompt\": combined_prompt,\r\n            \"max_tokens\": int(self.max_tokens),  # è½‰ç‚ºæ•´æ•¸\r\n            \"temperature\": float(self.temperature),  # è½‰ç‚ºæµ®é»æ•¸\r\n        }\r\n\r\n        try:\r\n            # ç™¼é€è«‹æ±‚åˆ° vLLM\r\n            response = requests.post(url, json=payload, headers=headers)\r\n            response.raise_for_status()\r\n            vllm_response = response.json()\r\n            generated_text = vllm_response[\"choices\"][0][\"text\"]\r\n        except requests.exceptions.RequestException as e:\r\n            generated_text = f\"Error calling vLLM: {str(e)}\"\r\n\r\n        # æ§‹å»º Message å°è±¡ï¼Œæ¨¡ä»¿ AIMessage\r\n        message = Message(\r\n            text=generated_text,\r\n            sender=\"AI\",\r\n            sender_name=\"vLLM\"\r\n        )\r\n        self.status = message\r\n        return message\r\n\r\n\r\n# å¯é¸ï¼šæ¸¬è©¦ä»£ç¢¼\r\nif __name__ == \"__main__\":\r\n    component = CustomVLLMComponent()\r\n    component.input_value = \"What is the capital of France?\"\r\n    component.prompt = \"Answer in one word.\"\r\n    component.model = \"/models/models--meta-llama--Llama-3.1-8B-Instruct/snapshots/manual-20250305\"\r\n    component.max_tokens = \"512\"\r\n    component.temperature = \"0.8\"\r\n    result = component.build_response()\r\n    print(result.text)",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input Value",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Additional input value to include in the request.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "max_tokens": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "256",
                "display_name": "Max Tokens",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "model": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "/models/models--meta-llama--Llama-3.1-8B-Instruct/snapshots/manual-20250305",
                "display_name": "Model",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The vLLM model path or name to use for inference.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "prompt": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "prompt",
                "value": "",
                "display_name": "Prompt",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The prompt to send to the vLLM model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": "0.9",
                "display_name": "Temperature",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Controls the randomness of the output (0.0 to 1.0).",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component to perform inference using a local vLLM model.",
            "icon": "brain",
            "base_classes": [
              "Message"
            ],
            "display_name": "vLLM Inference",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "response",
                "hidden": null,
                "display_name": "Response",
                "method": "build_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "prompt",
              "model",
              "max_tokens",
              "temperature"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "CustomVLLMComponent",
          "id": "CustomComponent-NnG1e"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 577
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "CustomComponent-NnG1e",
        "sourceHandle": "{Å“dataTypeÅ“:Å“CustomVLLMComponentÅ“,Å“idÅ“:Å“CustomComponent-NnG1eÅ“,Å“nameÅ“:Å“responseÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "ChatOutput-6Q1eR",
        "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-6Q1eRÅ“,Å“inputTypesÅ“:[Å“DataÅ“,Å“DataFrameÅ“,Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-6Q1eR",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CustomVLLMComponent",
            "id": "CustomComponent-NnG1e",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__CustomComponent-NnG1e{Å“dataTypeÅ“:Å“CustomVLLMComponentÅ“,Å“idÅ“:Å“CustomComponent-NnG1eÅ“,Å“nameÅ“:Å“responseÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ChatOutput-6Q1eR{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-6Q1eRÅ“,Å“inputTypesÅ“:[Å“DataÅ“,Å“DataFrameÅ“,Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "animated": false,
        "className": ""
      },
      {
        "source": "ChatInput-FKyB0",
        "sourceHandle": "{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-FKyB0Å“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "Prompt-WPdXW",
        "targetHandle": "{Å“fieldNameÅ“:Å“user_queryÅ“,Å“idÅ“:Å“Prompt-WPdXWÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "user_query",
            "id": "Prompt-WPdXW",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-FKyB0",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__ChatInput-FKyB0{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-FKyB0Å“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-Prompt-WPdXW{Å“fieldNameÅ“:Å“user_queryÅ“,Å“idÅ“:Å“Prompt-WPdXWÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-WPdXW",
        "sourceHandle": "{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-WPdXWÅ“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "CustomComponent-NnG1e",
        "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“CustomComponent-NnG1eÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CustomComponent-NnG1e",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-WPdXW",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__Prompt-WPdXW{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-WPdXWÅ“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-CustomComponent-NnG1e{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“CustomComponent-NnG1eÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "animated": false,
        "className": ""
      }
    ],
    "viewport": {
      "x": -58.7945668282739,
      "y": -288.7928311044682,
      "zoom": 0.6755011012074749
    }
  },
  "updated_at": "2025-03-05T08:53:42+00:00",
  "icon": "Braces",
  "name": "vllmåœ°ç«¯æ¨¡å‹åŸºæœ¬æ¨è«–",
  "icon_bg_color": null,
  "webhook": false
}